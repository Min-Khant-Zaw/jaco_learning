#! /usr/bin/env python

import itertools
import math
#import human_demonstrator#
import matplotlib.pyplot as plt
import numpy as np
import pickle
import sys

from trajopt_planner import Planner
import openrave_utils

home_pos = [103.366,197.13,180.070,43.4309,265.11,257.271,287.9276]
candlestick_pos = [180.0]*7

pick_basic = [104.2, 151.6, 183.8, 101.8, 224.2, 216.9, 310.8]
pick_basic_EEtilt = [104.2, 151.6, 183.8, 101.8, 224.2, 216.9, 200.0]
pick_shelf = [210.8, 241.0, 209.2, 97.8, 316.8, 91.9, 322.8]
place_lower = [210.8, 101.6, 192.0, 114.7, 222.2, 246.1, 322.0]
place_higher = [210.5,118.5,192.5,105.4,229.15,245.47,316.4]

place_lower_EEtilt = [210.8, 101.6, 192.0, 114.7, 222.2, 246.1, 400.0]
place_pose = [-0.46513, 0.29041, 0.69497] # x, y, z for pick_lower_EEtilt

T = 20.0

# feature constacts (update gains and max weights)
UPDATE_GAINS = {'table':2.0, 'coffee':2.0, 'laptop':100.0, 'human':20.0}
MAX_WEIGHTS = {'table':1.0, 'coffee':1.0, 'laptop':10.0, 'human':10.0}
FEAT_RANGE = {'table':0.6918574, 'coffee':1.87608702, 'laptop':1.00476554, 'human':3.2}

IMPEDANCE = 'A'
LEARNING = 'B'
DEMONSTRATION = 'C'

ALL = "ALL"						# updates all features
MAX = "MAX"						# updates only feature that changed the most
BETA = "BETA"					# updates beta-adaptive

class DemoJaco(object):

	def __init__(self, ID, method_type, record, feat_method, feat_list, feat_list_H, traj_cache=None, traj_rand=None):

		# method type - A=IMPEDANCE, B=LEARNING, C=DEMONSTRATION
		self.method_type = method_type

		# can be ALL, MAX, or BETA
		self.feat_method = feat_method

		# can be strings 'table', 'coffee', 'human', 'origin', 'laptop'
		self.feat_list = feat_list
		self.num_feats = len(self.feat_list)

		self.feat_list_H = feat_list_H
		self.num_feats_H = len(self.feat_list_H)

		# trajectory paths
		self.traj_cache = traj_cache
		self.traj_rand = traj_rand

		# record experimental data mode 
		if record == "F" or record == "f":
			self.record = False
		elif record == "T" or record == "t":
			self.record = True
		else:
			print("Oopse - it is unclear if you want to record data. Not recording data.")
			self.record = False

		self.weights = [0.0]*self.num_feats

		# ---- important discrete variables ---- #
		weights_span = [None]*self.num_feats
		for feat in range(0,self.num_feats):
			limit = MAX_WEIGHTS[self.feat_list[feat]]
			weights_span[feat] = list(np.arange(-limit, limit+.1, limit))

		weight_pairs = list(itertools.product(*weights_span))
		self.weights_list = [list(i) for i in weight_pairs]
		self.betas_list = [0.01, 0.03, 0.1, 0.3, 1.0]

		self.num_betas = len(self.betas_list)
		self.num_weights = len(self.weights_list)

		# Construct uninformed prior
		P_bt = np.ones((self.num_betas, self.num_weights))
		self.P_bt = 1.0/self.num_betas * P_bt

		# initialize start/goal based on features
		# by default for table and laptop, these are the pick and place
		pick = pick_basic_EEtilt
		place = place_lower
		if 'coffee' in self.feat_list:
			pick = pick_basic_EEtilt

		start = np.array(pick)*(math.pi/180.0)
		goal = np.array(place)*(math.pi/180.0)
		self.start = start
		self.goal = goal


		# create the trajopt planner representing the human demonstrator
		self.planner = Planner(self.feat_list_H, None, self.traj_cache)


	def inferDemo(self, human_weights):
		# stores the current trajectory we are tracking, produced by planner
		print("\n\n----------- SIMULATED HUMAN NOW PLANNING -----------")
		self.planner.replan(self.start, self.goal, human_weights, 0.0, T, 0.5, seed=None)
		self.traj = self.planner.waypts
		print("\n\nTHIS IS THE HUMAN TRAJ: " + str(self.traj) + "\n\n")

		self.learnWeights(self.traj)
		print("\n\nTHESE ARE THE WEIGHTS: ")
		print(self.P_bt)
		print("\n\n")
		self.visualize_posterior(self.P_bt)
		print("\n------------ SIMULATED DEMONSTRATION DONE ------------\n")
	

	def featurize(self, waypts):
		"""
		Computes the user-defined features for a given trajectory.
		---
		input trajectory, output list of feature values
		"""
		features = [self.planner.velocity_features(waypts)]
		features += self.num_feats * [[0.0] * (len(waypts)-1)]
		for index in range(0,len(waypts)-1):
			for feat in range(1,self.num_feats+1):
				if self.feat_list[feat-1] == 'table':
					features[feat][index] = self.planner.table_features(waypts[index+1])
				elif self.feat_list[feat-1] == 'coffee':
					features[feat][index] = self.planner.coffee_features(waypts[index+1])
				elif self.feat_list[feat-1] == 'human':
					features[feat][index] = self.planner.human_features(waypts[index+1],waypts[index])
				elif self.feat_list[feat-1] == 'laptop':
					features[feat][index] = self.planner.laptop_features(waypts[index+1],waypts[index])
				elif self.feat_list[feat-1] == 'origin':
					features[feat][index] = self.planner.origin_features(waypts[index+1])
		return features

	
	# ---- here's our algorithms for modifying the trajectory ---- #

	def learnWeights(self, traj):
	
		if traj is not None:
			old_features = self.featurize(self.traj)
			self.traj = traj
			new_features = self.featurize(self.traj)
			Phi_p = np.array([new_features[0]] + [sum(x) for x in new_features[1:]])
			print("\n\nPHI_P: ")
			print(Phi_p)
			print(" \n\n")
			Phi = np.array([old_features[0]] + [sum(x) for x in old_features[1:]])

			# Determine alpha and max theta
			update_gains = [0.0] * self.num_feats
			max_weights = [0.0] * self.num_feats
			feat_range = [0.0] * self.num_feats
			for feat in range(0, self.num_feats):
				update_gains[feat] = UPDATE_GAINS[self.feat_list[feat]]
				max_weights[feat] = MAX_WEIGHTS[self.feat_list[feat]]
				feat_range[feat] = FEAT_RANGE[self.feat_list[feat]]
			update = Phi_p - Phi

			if self.feat_method == ALL:
				# update all weights 
				curr_weight = self.weights - np.dot(update_gains, update[1:])
			elif self.feat_method == MAX:
				print("updating max weight")
				change_in_features = np.divide(update[1:], feat_range)

				# get index of maximal change
				max_idx = np.argmax(np.fabs(change_in_features))

				# update only weight of feature with maximal change
				curr_weight = [self.weights[i] for i in range(len(self.weights))]
				curr_weight[max_idx] = curr_weight[max_idx] - update_gains[max_idx]*update[max_idx+1]
			elif self.feat_method == BETA:
				# Now compute probabilities for each beta and theta in the dictionary
				P_xi = np.zeros((self.num_betas, self.num_weights))
				for (weight_i, weight) in enumerate(self.weights_list):
					for (beta_i, beta) in enumerate(self.betas_list):
						# Compute -beta*(weight^T*Phi(xi_H))
						numerator = -beta * np.dot([1] + weight, Phi_p)
						#import pdb;pdb.set_trace()

						# Calculate the integral in log space
						num_trajs = self.traj_rand.shape[0]
						logdenom = np.zeros((num_trajs,1))

						# Compute costs for each of the random trajectories
						for rand_i in range(num_trajs):
							curr_traj = self.traj_rand[rand_i]
							rand_features = self.featurize(curr_traj)
							Phi_rand = np.array([rand_features[0]] + [sum(x) for x in rand_features[1:]])

							if weight_i == 0 and beta_i == 0:
								print("PHI_RAND: ")
								print(Phi_rand)

							# Compute each denominator log
							logdenom[rand_i] = -beta * np.dot([1] + weight, Phi_rand)
						
						# Compute the sum in log space
						A_max = max(logdenom)
						expdif = logdenom - A_max
						denom = A_max + np.log(sum(np.exp(expdif)))

						# Get P(xi_H | beta, weight) by dividing them
						P_xi[beta_i][weight_i] = np.exp(numerator - denom)

				P_obs = P_xi / sum(sum(P_xi))

				# Compute P(weight, beta | xi_H) via Bayes rule
				posterior = np.multiply(P_obs, self.P_bt)

				# Normalize posterior
				posterior = posterior / sum(sum(posterior))

				# Compute optimal expected weight
				P_weight = sum(posterior, 0)
				curr_weight = np.sum(np.transpose(self.weights_list)*P_weight, 1)

				P_beta = np.sum(posterior, axis=1)
				self.beta = np.dot(self.betas_list,P_beta)
				
				self.P_bt = posterior
				print("observation model:", P_obs)
				print("posterior", self.P_bt)
				print("theta marginal:", P_weight)
				print("beta average:", self.beta)
				print("update:", update[1:])
			print("curr_weight after = " + str(curr_weight))

			# clip values at max and min allowed weights
			for i in range(self.num_feats):
				curr_weight[i] = np.clip(curr_weight[i], -max_weights[i], max_weights[i])

			self.weights = curr_weight
			return self.weights

	
	def visualize_posterior(self, post):
		fig2, ax2 = plt.subplots()
		plt.imshow(post, cmap='RdBu', interpolation='nearest')
		plt.colorbar()
		plt.xticks(range(len(self.weights_list)), list(self.weights_list), rotation = 'vertical')
		plt.yticks(range(len(self.betas_list)), list(self.betas_list))
		plt.xlabel(r'$\theta$')
		plt.ylabel(r'$\beta$')
		plt.title("Joint posterior belief")
		plt.show()


#### End class

def generate_traj_rand():
	traj_rand = []
	all_feats = "table"
	all_feats = [x.strip() for x in all_feats.split(',')]
	feat_list = []
	for i in range(len(all_feats)):
		feats = list(itertools.combinations(all_feats, i + 1))
		feat_list.extend(feats)
	
	planner = Planner([])
	for i in range(len(feat_list)):
		feats = list(feat_list[i])

		num_features = len(feats)
		planner.feat_list = feats

		# initialize start/goal based on features
		# by default for table and laptop, these are the pick and place
		pick = pick_basic_EEtilt
		place = place_lower
		if 'coffee' in feats:
			pick = pick_basic_EEtilt

		start = np.array(pick)*(math.pi/180.0)
		goal = np.array(place)*(math.pi/180.0)

		weights_span = [None]*num_features
		for feat in range(0,num_features):
			limit = MAX_WEIGHTS[feats[feat]]
			weights_span[feat] = list(np.arange(-limit, limit+.1, limit))

		weight_pairs = list(itertools.product(*weights_span))
		weight_pairs = [np.array(i) for i in weight_pairs]

		for (w_i, weights) in enumerate(weight_pairs):
			print(feats)
			print(weights)
			planner.replan(start, goal, list(weights), 0.0, T, 0.5)
			traj = planner.waypts
			traj_rand.append(traj)

	print(traj_rand)
	traj_rand = np.array(traj_rand)
	#savestr = "_".join(feat_list)
	savefile = "lalala.p"
	pickle.dump(traj_rand, open( savefile, "wb" ) )

	#return traj_rand


if __name__ == '__main__':

	generate_random_trajs = False

	if (generate_random_trajs):
		generate_traj_rand()
	else:
		ID = 0 #ID = int(sys.argv[1])
		method_type = "A" #method_type = sys.argv[2]
		record = "F" #record = sys.argv[3]
		feat_method = "BETA" #feat_method = sys.argv[4]
		feat_list = ["table"] #feat_list = [x.strip() for x in sys.argv[5].split(',')]
		feat_list_H = ["table"] #feat_list_H = [x.strip() for x in sys.argv[6].split(',')]
		traj_cache = traj_rand = None
	
		traj_rand = np.load('./lalala.p')
		#traj_rand = generate_traj_rand()

		#if sys.argv[7] != 'None':
		#	traj_cache = sys.argv[6]
		#if sys.argv[8] != 'None':
		#	traj_rand = sys.argv[7]

		robot = DemoJaco(ID,method_type,record,feat_method,feat_list,feat_list_H,traj_cache,traj_rand)
		human_weights = [1.0]*robot.num_feats_H
		robot.inferDemo(human_weights)

	


